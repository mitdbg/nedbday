<div class="content-container">
   <h1>
         North East Database Day 2017 <br />
         <small>Friday January 27th, 2017</small><br/>
         <small>MIT CSAIL Bulding 32 Room 123</small>
   </h1>
   <style>
   i {
   font-weight: bold;
   display: block;
   }
   </style>
   <h2 class="sponsorCallout">Special thanks to this year's sponsors</h2>
   <p class="sponsorCallout">
    <img src="images/logos/microsoft.jpg" width="180" /> &nbsp; &nbsp;
    <img src="images/logos/facebook.jpg" width="180" />
  </p>

   <table class="table table-bordered table-hover table-condensed programTable">
      <tbody>
         <tr>
            <th width="15%">Time</th>
            <th width="85%">Event</th>
         </tr>
         <tr>
            <td>8:15-9:00</td>
            <td><strong>Registration</strong></td>
         </tr>
         <tr>
            <td>9:00-9:10</td>
            <td><strong>Welcome and Acknowledgements</strong> (Sam Madden/Nesime Tatbul)</td>
         </tr>
         <tr>
            <td>9:10-10:00</td>
            <td><strong>Keynote 1: </strong>
              John Leonard (MIT Department of Mechanical Engineering and MIT CSAIL) <i>Self-Driving Vehicles, SLAM, and Databases</i><br/>
               <a href="javascript: toggleVisibility ('#keynote1A')">Click to toggle abstract and bio.</a>
               <div id="keynote1A" class="abstract" style="display: none;">
                  <h3>Abstract</h3>
                  <p>
Self-driving vehicles have the potential to revolutionize our transportation infrastructure, but also raise major challenges for research and policy development. Led by the efforts of Google and many leading automobile manufacturers, interest in the field of self-driving vehicles has surged in the past several years. In this talk, I will describe some of the core technologies of mobile robotics that underpin self-driving vehicles and other new applications of robotics, including: sensing, mapping, navigation, and path-planning. Despite recent progress, fully autonomous driving remains extremely difficult, with a number of difficult open questions. I will also describe the role of Simultaneous Localization and Mapping (SLAM) algorithms in self-driving, and will discuss potential connections of self-driving and SLAM with database algorithms and technology.
                  </p>
                  <h3>Bio</h3>
                  <p>
<b>John J. Leonard</b> is Samuel C. Collins Professor of Mechanical and Ocean Engineering and Associate Department Head for Research in the MIT Department of Mechanical Engineering. He is also a member of the MIT Computer Science and Artificial Intelligence Laboratory (CSAIL). His research addresses the problems of navigation and mapping for autonomous mobile robots and underwater vehicles. He is an IEEE Fellow (2014).
                  </p>
               </div>
            </td>
         </tr>
         <tr class="success">
            <td colspan="2" align="center"><strong>Session 1: Data Exploration (Chair: TBD)</strong></td>
         </tr>
         <tr>
            <td>10:00-10:20</td>
            <td>Raul Castro Fernandez (MIT), Samuel Madden (MIT), Michael Stonebraker (MIT) <i>Aurum: A Large Scale Data Discovery System Based on a Source Retrieval Algebra</i> 
            <br/>
            <a href="javascript: toggleVisibility ('#pa1A')">Click to toggle abstract.</a> 
               <div id="pa1A" class="abstract" style="display: none;">
                  <p>
Organizations face a data discovery problem when their analysts spend more time looking for relevant data than analyzing it. This problem has become commonplace in modern organizations as: i) data is stored across multiple storage systems, from databases to data lakes; ii) data scientists do not operate within the limits of well-defined schemas or a small number of data sources – instead, to answer complex questions they must access data spread across thousands of data sources. To address this problem we have built AURUM, a system to tackle data discovery problems. AURUM introduces a new discovery algebra, called the Source Retrieval Query Language (SRQL). In the talk we intend to show a demo of SRQL, as well as explain the techniques we used to make the system scale to large datasets that we are using with several of our collaborators.
                  </p>
               </div>
             </td>
         </tr>
         <tr>
            <td>10:20-10:40</td>
            <td>Andy Vidan (Composable Analytics, Inc.), Las Fiedler (Composable Analytics, Inc.) <i>Composable Dataflows and Queryviews</i> 
            <br/>
            <a href="javascript: toggleVisibility ('#pa1B')">Click to toggle abstract.</a> 
               <div id="pa1B" class="abstract" style="display: none;">
                  <p>
New data requirements demand flexibility and adaptability in the architecture to aggregate, process and analyze cross-silo data coming from an increasing number of sources. Organizations constrained to specific schema and traditional architectural models fail to manage the new data paradigm, and are inherently left behind in today’s Big Data era.
</p>
<p>
Here, we describe a new data and process integration platform originally developed at MIT Lincoln Laboratory that serves as a full-stack analytics platform with built-in services for data orchestration, automation and analytics. The platform enables organizations to rapidly adopt modern data architectures and accelerates data engineering, preparation and analysis. Built with a composable architecture that enables abstraction and integration of any software or analytical approach, the platform serves as a coherent analytics ecosystem for data management solutions that leverage disparate data sources, live feeds, and event data regardless of the amount, format or structure of the data.
</p>
<p>
At NEDB2017, we will present queryview, a new system that our team developed to enable users to interactively explore cross-silo data, and describe several use cases highlighting the use of complex dataflows and queryviews for social media analysis, network device monitoring and other applications. Querying a dataset often involves writing code-based queries or processing pipelines to extract raw data, which must then be summarized or visualized to review. Queryview is designed to facilitate querying a dataset interactively, within the context of viewing the data itself. This allows a user to act upon new insights more rapidly and iterate on an analysis directly from the current results. Through metadata discovery and creation, users are able to explore and model how disparate datasets relate, and extract relevant information across information systems.
</p>
<p>
Queryview was built to meet the following requirements:<br>
- Allow a user to discover and locate relevant data across an enterprise data warehouse and disparate information management systems;<br>
- Provide agility in data exploration;<br>
- Provide federated queries across datasets stored in separate data management systems.
</p>
<p>
Based on these requirements, we successfully designed and implemented queryview within the composable architecture. Composable extensions make it simple to connect to a variety of data sources, whether these are traditional relational databases, noSQL databases, or flat spreadsheet files. Abstracting the data from their particular storage mechanisms allows the user to explore the available data without requiring them to learn all of the individual toolsets typically necessary. Additionally, Composable’s extension framework allows the strategies for joining these datasets to be tuned and customized to facilitate efficient data loading.
                  </p>
               </div>
             </td>
         </tr>

         <tr>
            <td colspan="2">&nbsp;</td>
         </tr>
         <tr>
            <td>10:40-11:00</td>
            <td><strong>Coffee Break</strong></td>
         </tr>
         <tr>
            <td colspan="2">&nbsp;</td>
         </tr>

         <tr class="success">
            <td colspan="2" align="center"><strong>Session 2: Algorithms and Models (Chair: TBD)</strong></td>
         </tr>
         <tr>
            <td>11:00-11:20</td>
            <td>Akhil Arora (Xerox Research Centre India), Sainyam Galhotr (University of Massachusetts Amherst), Sayan Ranu (Indian Institute of Technology Delhi) <i>Debunking the Myths of Influence Maximization</i> 
            <br/>
            <a href="javascript: toggleVisibility ('#pa2A')">Click to toggle abstract.</a> 
               <div id="pa2A" class="abstract" style="display: none;">
                  <p>
Influence maximization (IM) on social networks is one of the most active areas of research in computer science. While various IM techniques proposed over the last decade have definitely enriched the field, unfortunately, experimental reports on existing techniques fall short in validity and integrity since many comparisons are not based on a common platform or merely discussed in theory. In this paper, we perform an in-depth benchmarking study of IM techniques on social networks. Specifically, we design a benchmarking platform, which enables us to evaluate and compare the existing techniques systematically and thoroughly under identical experimental conditions. Our benchmarking results analyze and diagnose the inherent deficiencies of the existing approaches and surface the open challenges in IM even after a decade of research. More fundamentally, we unearth and debunk a series of incorrect claims made by highly cited papers in the field of IM. Overall, this study establishes that there is no single state-of-the-art technique in IM. At best, a technique is the state of the art in only one aspect.
                  </p>
               </div>
             </td>
         </tr>

         <tr>
            <td>11:20-11:40</td>
            <td>Michael Stonebraker (MIT), Dong Deng (MIT), Michael Brodie (MIT) <i>Application-Database Co-Evolution: A New Design and Development Paradigm</i> 
            <br/>
            <a href="javascript: toggleVisibility ('#pa2B')">Click to toggle abstract.</a> 
               <div id="pa2B" class="abstract" style="display: none;">
                  <p>
In a recent IEEE paper, we discussed the concept of database decay. Specifically, as business conditions change in large enterprises, applications and/or the database schema must change. However, “in the wild” DBAs try very hard to minimize application maintenance by avoiding changing the schema. Instead they “kluge” the schema, thereby cause it to decay over time. In this short paper, we extend the discussion to consider application decay. If a DBA “does the right thing” and changes the schema to conform to well known database design principles, then extensive application maintenance is likely to be required. Patching applications will generally cause them to decay over time, as multiple patches, often by different programmers, will generate dirtier and dirtier code. Recent DBMS application frameworks support exactly this point of view. In our opinion, the two extremes (dirty data, clean application) and (clean data, dirty application) are both inferior to a strategy of co-evolution, which we present herein. We briefly outline a prototype co-evolution system and sketch its construction.
                  </p>
               </div>
             </td>
         </tr>

         <tr>
            <td>11:40-12:00</td>
            <td>Peter Mork (Noblis), Arnie Rosenthal (MITRE), Adriane Chapman (University of Southampton) <i>How We Learned to Stop Worrying and Embrace the Chaos</i> 
            <br/>
            <a href="javascript: toggleVisibility ('#pa2C')">Click to toggle abstract.</a> 
               <div id="pa2C" class="abstract" style="display: none;">
                  <p>
Semantic interoperability and seamless data integration have been research goals since the inception of electronic information management systems. And yet, after decades of research on ontology alignment, schema matching, mediators, and data exchange theory, these goals remain unattainable at anything approaching scale. In this presentation, we elucidate the tension between task-oriented and model-driven integration. The former emphasizes tackling the next task: great for demonstrating progress but often producing confusing simplifications. The latter approach requires the development of a shared conceptualization of the domain (the model) from which a wide range of information exchanges can be derived. Our research unifies these approaches with a common framework, which we outline in this submission.
                  </p>
               </div>
             </td>
         </tr>

         <tr>
            <td colspan="2">&nbsp;</td>
         </tr>
         <tr>
            <td>12:00-1:00</td>
            <td><strong>Lunch Break</strong></td>
         </tr>
         <tr>
            <td colspan="2">&nbsp;</td>
         </tr>

         <tr>
            <td>1:00-1:50</td>
            <td><strong>Keynote 2: </strong>
              David J. DeWitt (MIT CSAIL), Willis Lang (Microsoft Jim Gray Systems Lab) <i>Data Warehousing in the Cloud – The Death of Shared Nothing</i><br/>
               <a href="javascript: toggleVisibility ('#keynote2A')">Click to toggle abstract and bios.</a>
               <div id="keynote2A" class="abstract" style="display: none;">
                  <h3>Abstract</h3>
                  <p>
For more than 30 years, parallel database systems such as those from Teradata, Microsoft, Netezza, and Vertica have been employed a “shared-nothing” design in which storage and compute are co-located. Recently, several cloud-based data warehousing (DW) SAAS solutions have appeared including Amazon Redshift™, Microsoft’s SQL Data Warehouse™, the Snowflake Elastic Data Warehouse™ service, and Google’s BigQuery™. Except for Redshift, every cloud DW SAAS offering that we are aware of is based on a shared-storage design, and not the shared-nothing design paradigm. In this talk we explain why the marketplace for cloud DW offerings has exploded and is expected to continue to expand in the years to come. We will briefly describe each of the four services, highlighting their key architectural features and motivate why we expect that the designs based on a shared-storage paradigm to dominate going forward.
                  </p>
                  <h3>Bios</h3>
                  <p>
<b>David DeWitt</b> was a faculty member in the Computer Sciences Department at the University of Wisconsin-Madison from 1976 to 2008. In March 2008 he retired from UW-Madison and joined Microsoft as a Technical Fellow to start the Jim Gray Systems Laboratory. In the fall of 2016 he left Microsoft to move to Boston to join the MIT faculty. Professor DeWitt is a member of the National Academy of Engineering and a Fellow of the American Academy of Arts and Sciences. His pioneering contributions to the field of scalable database systems for “big data” were recognized by ACM with the 2009 Software Systems Award.
                  </p>
                  <p>
<b>Willis Lang</b> is a senior scientist working for Microsoft at the Jim Gray Systems Laboratory. He obtained his PhD from the University of Wisconsin-Madison. His researcher/developer role at Microsoft has resulted in product impact across Azure SQL Database, Azure DW, SQL Server, and APS in the areas of performance/scalability, SAAS efficiency, manageability, security, and fault tolerance.
                  </p>
               </div>
            </td>
         </tr>
         <tr class="success">
            <td colspan="2" align="center"><strong>Session 3: Scalable Analytics (Chair: TBD)</strong></td>
         </tr>
         <tr>
            <td>1:50-2:10</td>
            <td>Amin Saeidi (HPE Vertica), Ben Vandiver (HPE Vertica) Shreya Prasad (HPE Vertica) <i>Asynchronous and Event-based Query Execution for Efficient ETL on the Cloud</i> 
            <br/>
            <a href="javascript: toggleVisibility ('#pa3A')">Click to toggle abstract.</a> 
               <div id="pa3A" class="abstract" style="display: none;">
                  <p>
Query execution in a typical database system is synchronous, and long-running connection pooling is very common. While it is a requirement for many use cases, there are certain scenarios where a fire-and-forget or asynchronous model is more desirable. Serverless architecture which is becoming more popular especially for cloud deployments is one of them. Although it makes it possible for the users to run batch and real-time tasks without worrying about administration, it has its own limitation for long-running jobs such as bulk load. As part of this work, we propose an asynchronous query execution model for Vertica which integrates seamlessly with back-end services. We demonstrate how our solution reduces the costs significantly, and guarantees a constant runtime for growing workloads.
                  </p>
               </div>
             </td>
         </tr>

         <tr>
            <td>2:10-2:30</td>
            <td>Jeremy Kepner (MIT Lincoln Laboratory) <i>Enabling Scale-Up, Scale-Out, and Scale-Deep for Big Data</i> 
            <br/>
            <a href="javascript: toggleVisibility ('#pa3B')">Click to toggle abstract.</a> 
               <div id="pa3B" class="abstract" style="display: none;">
                  <p>
Big Data volume, velocity, and variety challenges have led to a proliferation of computing hardware and software solutions. Hyperscale data centers, accelerators, and programmable logic can deliver enormous performance via a wide range of analytic environments and data storage technologies. Effectively exploiting these capabilities for science and engineering requires mathematically rigorous interfaces that allow scientists and engineers to focus on their research and avoid rewriting software each time computing technology changes. The database community has pioneered high level, mathematically rigorous, declarative interfaces for decades. These database interfaces have allowed the database community to rapidly incorporate new technology innovations. Similarly, mathematically rigorous interfaces are at the core MIT Center for Engaging Supercomputing and enable the Center to deliver leading edge technologies to thousands of scientists and engineers. This talk discusses the rapidly evolving computing landscape and how mathematically rigorous interfaces are the key to exploiting advanced computing capabilities.
                  </p>
               </div>
             </td>
         </tr>

         <tr>
            <td colspan="2">&nbsp;</td>
         </tr>
         <tr>
            <td>2:30-2:50</td>
            <td><strong>Coffee Break</strong></td>
         </tr>
         <tr>
            <td colspan="2">&nbsp;</td>
         </tr>

         <tr class="success">
            <td colspan="2" align="center"><strong>Session 4: Storage Management (Chair: TBD)</strong></td>
         </tr>
         <tr>
            <td>2:50-3:10</td>
            <td>Anil Shanbhag (MIT) <i>Adaptive Partitioning for Distributed Query Processing </i> 
            <br/>
            <a href="javascript: toggleVisibility ('#pa4A')">Click to toggle abstract.</a> 
               <div id="pa4A" class="abstract" style="display: none;">
                  <p>
Big data analytics often involves selections over multiple columns and complex joins over two or more tables. These operations are expensive as they involve large amounts of data being read from disk, and because of data shuffling across the network. Many techniques based on data partitioning have been proposed to reduce the amount of data that must be accessed, often focusing on finding the best partitioning scheme for a particular workload, rather than adapting to changes in the workload over time. In this talk, we present AdaptDB, an adaptive storage manager for analytical database workloads in a distributed setting. The key idea is to build and maintain partitioning tree(s) on top of the dataset. The partitioning tree(s) partitions the dataset on many different attributes partially, allowing us to answer queries with predicates by reading a subset of the data. AdaptDB also introduces a novel hyper-join to join two datasets partially partitioned as above. Hyper- join avoids expensive data shuffling by identifying storage blocks of the joining tables that overlap on the join attribute, and only joining those blocks. Hyper-join performs well when each block in one table overlaps with few blocks in the other table, since that will minimize the number of blocks that have to be accessed. The initial partitioning tree is created without requiring an upfront query workload and AdaptDB adapts it over time by incrementally modifying subtrees based on user queries using re-partitioning. A prototype of AdaptDB running on top of Spark improves query performance by 2-3x on TPC-H as well as real-world dataset, versus a system that employs scans and shuffle-joins.
                  </p>
               </div>
             </td>
         </tr>

         <tr>
            <td>3:10-3:30</td>
            <td>Yoshinori Matsunobu (Facebook) <i>MyRocks: A Space and Write Optimized MySQL Database</i> 
            <br/>
            <a href="javascript: toggleVisibility ('#pa4B')">Click to toggle abstract.</a> 
               <div id="pa4B" class="abstract" style="display: none;">
                  <p>
Facebook created and open-sourced a next generation OLTP SQL database on modern Flash storage called MyRocks -- RocksDB storage engine for MySQL. Facebook has used MySQL (InnoDB) for many years, and InnoDB is a great general purpose database and in many cases is the best fit. Facebook wanted more space to write optimized databases that work more efficiently on Flash. There was room to write optimized NoSQL databases outside of MySQL ecosystem, but the company wanted to utilize existing MySQL assets like client programs relying on SQL and MySQL connectors, Replication, and administration tools. To meet these requirements, it created a new MySQL storage engine on top of RocksDB (http://rocksdb.org/) -- MyRocks (https://github.com/facebook/mysql-5.6). In this session, the speaker will introduce MyRocks, its architecture, and how Facebook is using MyRocks.
                  </p>
               </div>
             </td>
         </tr>

         <tr>
            <td>3:30-3:50</td>
            <td>Manos Athanassoulis (Harvard), Zheng Yan (University of Maryland), Stratos Idreos (Harvard)<i>UpBit: Scalable In-Memory Updatable Bitmap Indexing</i> 
            <br/>
            <a href="javascript: toggleVisibility ('#pa4C')">Click to toggle abstract.</a> 
               <div id="pa4C" class="abstract" style="display: none;">
                  <p>
Bitmap indexes are widely used in both scientific and commercial databases. They bring fast read performance for specific types of queries, such as equality and selective range queries. A major drawback of bitmap indexes, however, is that supporting updates is particularly costly. Bitmap indexes are kept compressed to minimize storage footprint; as a result, updating a bitmap index requires the expensive step of decoding and then encoding a bitvector. Today, more and more applications need support for both reads and writes, blurring the boundaries between analytical processing and transaction processing. This requires new system designs and access methods that support general updates and, at the same time, offer competitive read performance. In this project, we propose scalable in-memory Updatable Bitmap indexing (UpBit), which offers efficient updates, without hurting read performance. UpBit relies on two design points. First, in addition to the main bitvector for each domain value, UpBit maintains an update bitvector, to keep track of updated values. Effectively, every update can now be directed to a highly-compressible, easy-toupdate bitvector. While update bitvectors double the amount of uncompressed data, they are sparse, and as a result their compressed size is small. Second, we introduce fence pointers in all update bitvectors which allow for efficient retrieval of a value at an arbitrary position. Using both synthetic and real-life data, we demonstrate that UpBit significantly outperforms state-of-the-art bitmap indexes for workloads that contain both reads and writes. In particular, compared to update-optimized bitmap index designs UpBit is 15−29x faster in terms of update time and 2.7x faster in terms of read performance. In addition, compared to read-optimized bitmap index designs UpBit achieves efficient and scalable updates (51-115x lower update latency), while allowing for comparable read performance, having up to 8% overhead.
                  </p>
               </div>
             </td>
         </tr>

         <tr>
            <td>3:50-4:10</td>
            <td>Kayhan Dursun (Brown), Carsten Binnig (Brown), Ugur Cetintemel (Brown), Tim Kraska (Brown) <i>Revisiting Reuse in Main Memory Database Systems</i> 
            <br/>
            <a href="javascript: toggleVisibility ('#pa4D')">Click to toggle abstract.</a> 
               <div id="pa4D" class="abstract" style="display: none;">
                  <p>
Reusing intermediates in databases to speed-up analytical query processing has been studied in the past. Existing solutions typically require intermediate results of individual operators be materialized in memory during query processing to be considered for reuse in subsequent queries. However, these approaches are not optimal for modern main memory databases. First, inserting additional materialization operations into a query plan results in an additional overhead that first needs to be amortized by subsequent queries that can reuse the materialized intermediates. Second, modern main memory DBMSs are typically heavily optimized for cache- and register-locality and therefore attempt to minimize pipeline breakers.
</p>
<p>
To that end, adding additional materialization operations into a query plan not only add additional traffic to the memory bus but more importantly prevent the important cache- and register-locality, which results in performance penalties. Consequently, the benefits of materialization-based reuse techniques heavily depend on the characteristics of the workload: i.e., how much overlap between queries of a given workload exists. In the worst case, if the overlap is low the extra cost caused by materialization operations might even result in an overall performance degradation for analytical workloads.
</p>
<p>
The goal of this paper is to revisit ”reuse” in the context of modern main memory databases. The main idea is to leverage internal data structures for reuse that are materialized anyway by pipeline breakers during query execution. This way, reuse comes for free without any additional execution costs. Moreover, as we will show in our experiments, a result reuse becomes more robust towards workloads with different reuse potentials and provides benefits for a wider range of workloads even if the overlap between queries is not that high.
</p>
<p>
In this talk, we present a new main memory database system called HashStash that implements the reuse of internal data structures. The focus of this work is on the most common internal data structure, hash tables (HTs), as found in hash-join and hash-aggregate operations. We leave other operators and data structures (e.g., trees) for future work.
                  </p>
               </div>
             </td>
         </tr>

         <tr>
            <td>4:10-4:30</td>
            <td>Joy Arulraj (CMU), Andrew Pavlo (CMU)<i>How to Build a Non-Volatile Memory Database Management System</i> 
            <br/>
            <a href="javascript: toggleVisibility ('#pa4E')">Click to toggle abstract.</a> 
               <div id="pa4E" class="abstract" style="display: none;">
                  <p>
The difference in the performance characteristics of volatile (DRAM) and non-volatile storage devices (HDD/SSDs) influences the design of database management systems (DBMSs). The key assumption has always been that the latter is much slower than the former. This affects all aspects of a DBMS's runtime architecture. But the arrival of new non-volatile memory (NVM) storage that is almost as fast as DRAM with fine-grained read/writes invalidates these previous design choices. In this talk, we provide an outline on how to build a new DBMS given the changes to hardware landscape due to NVM. We survey recent developments in this area, and discuss the lessons learned from prior research on designing NVM database systems. We highlight a set of open research problems, and present ideas for solving some of them.
                  </p>
               </div>
             </td>
         </tr>
         <tr>
            <td colspan="2">&nbsp;</td>
         </tr>
         <tr>
            <td>4:30 PM</td>
            <td><a href="#posters"><strong>Poster Session</strong></a> and Appetizers / Drinks (Building 32, R&D Commons, 4th Floor, Gates Tower)</td>
         </tr>
         <tr>
            <td>6:00 PM</td>
            <td>Adjourn</td>
          </tr>
      </tbody>
   </table>
</div>
