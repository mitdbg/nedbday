<div class="content-container">
   <h1>
      North East Database Day Program
   </h1>
   <h2 class="sponsorCallout">Sponsors</h2>
   <p class="sponsorCallout">Special thanks to this year's sponsors:<br/> <br/> <img src="images/logos/microsoft.jpg" width="180" /></p>
   <p class="programDate">January 28, 2016</p>
   <table class="table table-bordered table-hover table-condensed programTable">
      <tbody>
         <tr>
            <th width="15%">Time</th>
            <th width="85%">Event</th>
         </tr>
         <tr>
            <td>8:15-9:00am</td>
            <td><strong>Registration</strong></td>
         </tr>
         <tr>
            <td>9:00-9:10am</td>
            <td><strong>Welcome</strong> (  )</td>
         </tr>
         <tr>
            <td>9:10-9:20am</td>
            <td>Sponsor Acknowledgements</td>
         </tr>
         <tr>
            <td>9:20-10:10</td>
            <td><strong>Keynote1: </strong>
              D. Richard Hipp (SQLite).  <i>Title TBA</i><br/>
               <a href="javascript: toggleVisibility ('#keynote1A')">Click to toggle bio.</a>
               <div id="keynote1A" class="abstract" style="display: none;">
                  <h3>Abstract</h3>
                  <p>TBA</p>
                  <h3>Bio</h3>
                  <p>Dwayne Richard Hipp (born April 9, 1961) is the architect and primary author of SQLite as well as the Fossil SCM. He and his wife, Ginger G. Wyrick, currently live and work in Charlotte, North Carolina. He also authored the Lemon Parser Generator and CVSTrac. CVSTrac became the inspiration for Trac. He was also a member of the Tcl core team.
                  </p>
               </div>
            </td>
         </tr>
         <tr>
            <td>10:10-10:30</td>
            <td>Coffee Break</td>
         </tr>
         <!--
         <tr class="success">
            <td colspan="2" align="center"><strong>Session 1: New Hardware and Applications</strong></td>
         </tr>
         <tr>
            <td>10:30-10:50</td>
            <td>Kristin Tufte (Portland State University) <i>Adventures in Transportation from a (Big) Data Perspective</i> <br/><a href="javascript: toggleVisibility ('#pa1A')">Click to toggle abstract.</a> | <a href="./pdf/Paper40.pdf" target="_new">Click to view full paper.</a>
               <div id="pa1A" class="abstract" style="display: none;">
                  <h3>Kristin Tufte*, Portland State University</h3>
                  <p>Transportation is a part of our daily lives. It is well known that transportation is an important part of our lives and economy and has a large impact on the environment. What may be less well known is how diverse and interesting the data generated by transportation infrastructure is.  This talk gives a tour through transportation data sources from a data management perspective. Data sources are described and issues in obtaining and managing that data are discussed. Transportation data is an excellent example of Big Data Variety - we describe the variations in transportation data, ranging from simple format differences to more complex semantic differences and the need to combine data across different, varied sources to provide a complete picture of the transportation system. In addition to the tour of data sources, we discuss how the transportation data is used in practice and provide ideas of how it may be used in the future. We discuss very preliminary solutions for archiving this data, but more importantly we highlight areas where (big data) computer science research is applicable in the transportation data domain.</p>
               </div>
             </td>
         </tr>
         <tr>
            <td>10:50-11:10</td>
            <td>Paul Brown (Paradigm4 Inc) <i>A Survey of Scientific Applications using SciDB</i> <br/><a href="javascript: toggleVisibility ('#pa2A')">Click to toggle abstract.</a> | <a href="./pdf/Paper41.pdf" target="_new">Click to view full paper.</a>
               <div id="pa2A" class="abstract" style="display: none;">
                  <h3>Paul Brown*, Paradigm4 Inc</h3>
                  <p>While SciDB is gaining popularity among commercial software developers and data analysts charged with building ``Big Data'' applications, the platform was conceived as a tool for scientists. Here, we review a number of purely scientific applications of SciDB; bioinformatics at the NIH, experimental physics at NERSC, and remote sensing at INPE. We describe each project in terms of its scientific objectives, the quantity and character of the data involved, the analytic workload, and its hardware architecture. We conclude the talk with a general summary of what these projects have in common, and comment on what experience building these applications implies for data management in the Internet-of-Things (IoT); a computing environment where all interesting data is generated by machines.</p>
               </div>
             </td>
         </tr>
         <tr>
            <td>11:10-11:30</td>
            <td>Carsten Binnig, Ugur Cetintemel, Tim Kraska, Stan Zdonik (Brown) <i>I-Store: Data Management for Fast Networks</i> <br/><a href="javascript: toggleVisibility ('#pa3A')">Click to toggle abstract.</a> | <a href="./pdf/Paper51.pdf" target="_new">Click to view full paper.</a>
               <div id="pa3A" class="abstract" style="display: none;">
                  <h3>Carsten Binnig*, Brown University; Ugur Cetintemel, Brown University; Tim Kraska, Brown University; Stan Zdonik, Brown University</h3>
                  <p>Existing distributed data management systems typically assume that the network is a major bottleneck.  Consequently, avoiding remote data transfers is an important design aspect of existing systems. With modern RDMA-capable networks such as Infiniband FDR/EDR the before mentioned design decisions become obsolete. Modern interconnects allow data to transfer across machines almost as fast as from the CPU to memory.  In this paper, we revisit design decisions for distributed data management systems for OLTP workloads as well as for OLAP workloads under the assumption that communication between servers is essentially free.</p>
               </div>
             </td>
         </tr>
         <tr>
            <td>11:30-11:50</td>
            <td>Xiangyao Yu (MIT), George Bezerra (MIT), Andrew Pavlo (CMU), Srinivas Devadas (MIT), Michael Stonebraker (MIT) <i>Staring into the Abyss: An Evaluation of Concurrency Control with One Thousand Cores</i> <br/><a href="javascript: toggleVisibility ('#pa4A')">Click to toggle abstract.</a> | <a href="./pdf/Paper17.pdf" target="_new">Click to view full paper.</a>
               <div id="pa4A" class="abstract" style="display: none;">
                  <h3>Xiangyao Yu*, MIT; George Bezerra, MIT; Andrew Pavlo, CMU; Srinivas Devadas, MIT; Michael Stonebraker, MIT</h3>
                  <p>Computer architectures are moving towards an era dominated by many-core machines with dozens or even hundreds of cores on a single chip. This unprecedented level of on-chip parallelism introduces a new dimension to scalability that current database management systems (DBMSs) were not designed for. In particular, as the number of cores increases, the problem of concurrency control becomes extremely challenging. With hundreds of threads running in parallel, the complexity of coordinating competing accesses to data will likely diminish the gains from increased core counts.  To better understand just how unprepared current DBMSs are for future CPU architectures, we performed an evaluation of concurrency control for on-line transaction processing (OLTP) workloads on many-core chips. We implemented seven concurrency control algorithms on a main-memory DBMS and using computer simulations scaled our system to 1024 cores. Our analysis shows that all algorithms fail to scale to this magnitude but for different reasons. In each case, we identify fundamental bottlenecks that are independent of the particular database implementation and argue that even state-of-the-art DBMSs suffer from these limitations. We conclude that rather than pursuing incremental solutions, many-core chips may require a completely redesigned DBMS architecture that is built from ground up and is tightly coupled with the hardware.</p>
               </div>
             </td>
         </tr>
         <tr>
            <td colspan="2">&nbsp;</td>
         </tr>

        -->


         <tr>
            <td>11:50-12:50</td>
            <td><strong>Lunch (Outside 32-123)</strong></td>
         </tr>
         <tr>
            <td colspan="2">&nbsp;</td>
         </tr>
         <tr>
            <td>1:00-1:50</td>
            <td><strong>Keynote2: </strong>
               Le Cong (MIT). 
               <i>Novel Genome Engineering Tools Based on CRISPR-Cas 
               System and Their Application and Intersection with Genomics Analysis
                </i> <br/>
                <a href="javascript: toggleVisibility ('#keynote2A')">Click to toggle bio.</a>
               <div id="keynote2A" class="abstract" style="display: none;">
                  <h3>Bio</h3>
                  <p>
                  Dr. Le Cong obtained his B.S. with highest honor from Tsinghua University, his Ph.D. from Harvard University, and is currently a Postdoctoral Associate at the Broad Institute of MIT and Harvard. He completed thesis work mainly in Dr. Feng Zhang’s lab, where he did pioneering studies on genetic and epigenetic engineering, focusing on developing technologies based on TALE and CRISPR-Cas systems and adapting them for gene therapy applications. His work was the first to demonstrate CRISPR-Cas9 genome editing in eukaryotic cells (Cong et al. Science. 2013), and is co-inventor of multiple patents on related technologies. He is now working on single-cell genomics and systems biology in Dr. Aviv Regev's group. He has published in many high-impact journals including Science, Nature, Cell, Nature Biotechnology, and written for Springer’s Book Series Neuromethods and Methods in Molecular Biology. He is recipient of multiple awards and fellowships including the HHMI International Student Research Fellowship, the CRI Irvington Postdoctoral Fellowships Award, among others.
                  </p>
               </div>
            </td>
         </tr>










         <!--
         <tr class="success">
            <td colspan="2" align="center"><strong>Session 2: Graphs and DB Design</strong></td>
         </tr>
         <tr>
            <td>1:50-2:10</td>
            <td>Antonio Maccioni (Roma Tre Uni / Yale Uni), Daniel Abadi (Yale University) <i>On Compressing Graph Databases</i> <br/><a href="javascript: toggleVisibility ('#pa5A')">Click to toggle abstract.</a> | <a href="./pdf/Paper12.pdf" target="_new">Click to view full paper.</a>
               <div id="pa5A" class="abstract" style="display: none;">
                  <h3>Antonio Maccioni*, Roma Tre Uni / Yale Uni; Daniel Abadi, Yale University</h3>
                  <p>Distributed and parallel databases are not always a scalable solution for graphs because of the low locality in the  data matching the query. A different approach for scalability is to consider compressed versions of the input graph in order to reduce the cost of join operations at query time. These methods proved to be effective when the queries are given in advance but are not general enough to be adopted since we cannot reconstruct the original graph with decompression. This means that the results of the query are approximations of the exact answers. We want to discuss with the audience a novel compression technique that enables the database engine to evaluate graph queries (e.g., graph pattern matching queries) in an exact way. Preliminary experiments show that our approach is scalable with respect to the size of the graph and that this method can be employed as a layer over existing database systems with minimal effort.</p>
               </div>
             </td>
         </tr>
         <tr>
            <td>2:10-2:30</td>
            <td>Jeremy Kepner (MIT) <i>Associative Arrays: Unified Mathematics for Spreadsheets, Databases, Matrices, and Graphs</i> <br/><a href="javascript: toggleVisibility ('#pa6A')">Click to toggle abstract.</a> | <a href="./pdf/Paper7.pdf" target="_new">Click to view full paper.</a>
               <div id="pa6A" class="abstract" style="display: none;">
                  <h3>Jeremy Kepner*, MIT</h3>
                  <p>Data processing systems impose multiple views on data as it is processed by the system.  These views include spreadsheets, databases, matrices, and graphs.  The common theme amongst these views is the need to store and operate on data as whole sets instead of as individual data elements. This work describes a common mathematical representation of these data sets (associative arrays) that applies across a wide range of applications and technologies.  Associative arrays unify and simplify these different approaches for representing and manipulating data into common two-dimensional view of data. Specifically, associative arrays (1) reduce the effort required to pass data between steps in a data processing system, (2) allow steps to be interchanged with full confidence that the results will be unchanged, and (3) make it possible to recognize when steps can be simplified or eliminated.  Most database system naturally support associative arrays via their tabular interfaces.  The D4M implementation of associative arrays uses this feature to provide a common interface across SQL, NoSQL, and NewSQL databases.</p>
               </div>
             </td>
         </tr>
         <tr>
            <td>2:30-2:50</td>
            <td>Barzan Mozafari (Michigan) <i>CliffGuard: Towards Workload-Resilient Database Designs</i> <br/><a href="javascript: toggleVisibility ('#pa7A')">Click to toggle abstract.</a> | <a href="./pdf/Paper50.pdf" target="_new">Click to view full paper.</a>
               <div id="pa7A" class="abstract" style="display: none;">
                  <h3>Barzan Mozafari*, University of Michigan</h3>
                  <p>A fundamental problem in database systems is choosing the best physical design, i.e., a small set of auxiliary structures that en- able the fastest execution of future queries. Almost all commer- cial databases come with designer tools that create a number of indices or materialized views (together comprising the physical de- sign) that they exploit during query processing. Existing designers are what we call nominal; that is, they assume that their input pa- rameters are precisely known and equal to some nominal values. For instance, since future workload is often not known a priori, it is common for these tools to optimize for past workloads in hopes that future queries and data will be similar. In practice, however, these parameters are often noisy or missing. Since nominal de- signers do not take the influence of such uncertainties into account, they find designs that are sub-optimal and remarkably brittle. Of- ten, as soon as the future workload deviates from the past, their overall performance falls off a cliff, leading to customer discontent and expensive re-designs. Thus, we propose a new type of database designer that is robust against parameter uncertainties, so that over- all performance degrades more gracefully when future workloads deviate from the past. Users express their risk tolerance by de- ciding on how much nominal optimality they are willing to trade for attaining their desired level of robustness against uncertain sit- uations. To the best of our knowledge, this project is the first to adopt the recent breakthroughs in the theory of robust optimization to build a practical framework for solving some of the most fundamental problems in databases, replacing today's brittle designs with a principled world of robust designs that can guarantee predictable and consistent performance.</p>
               </div>
             </td>
         </tr>
         <tr>
            <td>2:50-3:10</td>
            <td>Coffee Break</td>
         </tr>
         <tr class="success">
            <td colspan="2" align="center"><strong>Session 3: Big Data and Real-time Analytics</strong></td>
         </tr>
         <tr>
            <td>3:10-3:30</td>
            <td> Alekh Jindal, Samuel Madden (MIT) <i>Preparing Data For The Data Lake</i> <br/><a href="javascript: toggleVisibility ('#pa8A')">Click to toggle abstract.</a> | <a href="./pdf/Paper45.pdf" target="_new">Click to view full paper.</a>
               <div id="pa8A" class="abstract" style="display: none;">
                  <h3>Alekh Jindal*, MIT; Samuel Madden, MIT</h3>
                  <p>Data preparation is increasingly becoming one of the biggest challenges in processing big data. While recent tools such as Tamer and Trifacta address the problem of integrating and cleaning the datasets as they come in, preparing these datasets for efficient processing over a variety of query workloads is still challenging. In this talk, I will discuss these challenges and describe our tool which allows for fine-grained data preparation, via a data preparation plan, and efficiently runs this plan while uploading the data to HDFS.</p>
               </div>
             </td>
         </tr>
         <tr>
            <td>3:30-3:50</td>
            <td>Yuan Yuan, Kaibo Wang, Rubao Lee, Xiaoning Ding, Xiaodong Zhang (Ohio State)<i>BCC: Reducing False Aborts in Optimistic Concurrency Control with Affordable Cost for In-Memory Databases</i> <br/><a href="javascript: toggleVisibility ('#pa9A')">Click to toggle abstract.</a> | <a href="./pdf/Paper32.pdf" target="_new">Click to view full paper.</a>
               <div id="pa9A" class="abstract" style="display: none;">
                  <h3>Yuan Yuan*, ; Kaibo Wang, ; Rubao Lee, ; Xiaoning Ding, New Jersey Institute of Techno; Xiaodong Zhang</h3>
                  <p>The Optimistic Concurrency Control (OCC) method has been demonstrated to provide high transaction throughputs in several recent in-memory database studies. OCC will abort a transaction if the transaction's read set has been changed by other concurrent transactions. OCC works well as long as transaction contention is low. However, it will cause unnecessary transaction aborts and significantly degrade the database's throughput when transaction contention is high. In this work, we propose a new concurrency control method BCC that is able to more precisely determine whether a transaction should be aborted. We implement BCC in Silo. Our evaluations demonstrate that BCC have much better transaction throughput  compared to OCC when transaction contention is high while having comparable performance with OCC for low contention workloads.</p>
               </div>
             </td>
         </tr>
         <tr>
            <td>3:50-4:10</td>
            <td>John Hugg (VoltDB) <i>Friends don't let Friends use the Lambda Architecture</i> <br/><a href="javascript: toggleVisibility ('#pa10A')">Click to toggle abstract.</a> | <a href="./pdf/Paper39.pdf" target="_new">Click to view full paper.</a>
               <div id="pa10A" class="abstract" style="display: none;">
                  <h3>John Hugg*, VoltDB Inc.</h3>
                  <p>Recently, there have been a number of systems developed to tackle the intersection of streaming and big data. Nathan Marz has championed the Lambda Architecture as a recipe for combining speed and batch processing to tackle these problems. Today, it's hard to go to a trendy big data conference without hearing a talk about how a complex, interdependent Lambda system solved a problem in heroic fashion with only a modicum of war scars and hefty AWS bill.  In this talk, we will prove, by counterexample, that the Lambda Architecture is bad and should feel bad. We will examine an recent, popular and non-fictional Lambda conference talk. We will then show how the same problem can be solved using VoltDB in a tiny fraction of the code, with many fewer nodes and with drastically reduced operational complexity. Finally we will argue the results are generally generalizable, i.e. not specific to the one example shown.</p>
               </div>
             </td>
         </tr>
         <tr>
            <td>4:10-4:30</td>
            <td>Jennie Duggan (Northwestern), Aaron Elmore (U. Chicago), Tim Kraska (Brown), Samuel Madden (MIT), Tim Mattson (Intel), Michael Stonebraker (MIT) <i>The BigDawg Architecture and Reference Implementation</i> <br/><a href="javascript: toggleVisibility ('#pa11A')">Click to toggle abstract.</a> | <a href="./pdf/Paper54.pdf" target="_new">Click to view full paper.</a>
               <div id="pa11A" class="abstract" style="display: none;">
                  <h3>Jennie Duggan*, Northwestern University; Aaron Elmore, Univ. of Chicago; Tim Kraska, Brown University; Samuel Madden, MIT; Tim Mattson, Intel Corp; Michael Stonebraker, MIT</h3>
                  <p>This paper presents the reference implementation of a new architecture for future "Big Data" applications.  Such applications require "big analytics" as one might expect, but they also require real-time streaming support, real-time analytics, data visualization, and cross-storage queries.  We are guided by the principle "one size does not fit all", and we build on top of three storage engines, each designed for specialized use cases.  In addition, we demonstrate novel support for querying across multiple storage engines as well as pioneering solutions to data visualization.  In the remainder of this short paper, we describe the first of three BigDawg reference implementations, Bulldog.  In the next two years we expect to follow with Pitbull and Rottweiler releases.</p>
               </div>
             </td>
         </tr>
         <tr>
            <td colspan="2">&nbsp;</td>
         </tr>
        -->
         <tr>
            <td>4:30 PM</td>
            <td><a href="#posters"><strong>Poster Session</strong></a> and Appetizers / Drinks (Building 32, R&D Commons, 4th Floor, Gates Tower)</td>
         </tr>
         <tr>
            <td>6:30 PM</td>
            <td>Adjourn</td>
          </tr>
      </tbody>
   </table>
</div>
